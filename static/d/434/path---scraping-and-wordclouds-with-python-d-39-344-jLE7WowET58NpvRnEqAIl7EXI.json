{"data":{"site":{"siteMetadata":{"title":"Kristina Maceković","author":"Kristina Maceković"}},"markdownRemark":{"id":"5f8a6a12-f87c-5281-a019-e83d69e7c7cc","excerpt":"Recently I started going through Harvard’s  CS109 class , which aims to be a practical and broad intro to data science (using python). I’m enjoying it a lot…","html":"<p>Recently I started going through Harvard’s <a href=\"http://cs109.github.io/2015/\">CS109 class</a>, which aims to be a practical and broad intro to data science (using python). I’m enjoying it a lot, and it has definitely given me a push to do something with python (finally!).</p>\n<p>A few months ago, I was intrigued by the beautiful SQL lessons at <a href=\"https://selectstarsql.com\">SELECT * SQL</a>—mainly because of the excellent content, but also because of the intriguing data set. The data set deals with last statements of prisoners on death row. It is definitely a controversial topic, but I think an interesting one that can only spark productive discussion. What is really interesting is that such data <em>exists</em> and is <em>publicly accessible.</em></p>\n<p>For the little project, I decided to scrape the data and do some type of short analysis that could be impactful. I ended up doing a word cloud of the statements (inspiration was <a href=\"http://www.goodbyewarden.com/\">Goodbye, Warden</a>, data is <a href=\"https://www.tdcj.texas.gov/death_row/dr_executed_offenders.html\">here</a> and is the same as for SELECT * SQL). So, lets start.</p>\n<h1>The Process</h1>\n<p>Import the relevant modules.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    <span class=\"token comment\"># module for http requests</span>\n    <span class=\"token keyword\">import</span> requests\n    <span class=\"token comment\"># module for handling markup objects</span>\n    <span class=\"token keyword\">from</span> bs4 <span class=\"token keyword\">import</span> BeautifulSoup\n    <span class=\"token comment\"># visualization module</span>\n    <span class=\"token keyword\">import</span> matplotlib\n    <span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n    <span class=\"token comment\"># print out graphics in the document</span>\n    <span class=\"token operator\">%</span>matplotlib inline\n    <span class=\"token comment\"># module that implements word clouds</span>\n    <span class=\"token keyword\">from</span> wordcloud <span class=\"token keyword\">import</span> WordCloud</code></pre></div>\n<p>Get the site with the links to all the prisoner information. To get a manageable version, apply BeautifulSoup to the original results. The prettify function can be used to get a more human-readable version of the text.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    main_pg_txt <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"https://www.tdcj.texas.gov/death_row/dr_executed_offenders.html\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>text\n    <span class=\"token comment\"># main_pg_txt</span>\n    main_pg_html <span class=\"token operator\">=</span> BeautifulSoup<span class=\"token punctuation\">(</span>main_pg_txt<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># main_pg_html.prettify()</span>\n    <span class=\"token comment\"># main_pg_html</span></code></pre></div>\n<p>Now it’s time to figure out how to access the last statements. Here the crucial tools is the dev tools in the browser (element inspector in particular). I was expecting the “Last Statement” to have some type of class or id, but unfortunately it didn’t have, so I had to find a common structure and use that instead.</p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/45718b260d0250147cd97ebff76e9426/1b01e/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 55.833333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAACb0lEQVQoz43Q3UvTURjA8f0TIr7k617c3PS3Tc0ZFjb3om6mSNi/0EXdddddEARFUARBVxFYUImllkaaqaOMiaWu1MRN82VmOt1cbtb27eznC9lVBz48z3nO7/dwnqPwTPjxTAQYHvdz40Evl24+4u6TAfpGZ3k79hXf7AIz80G+rYbwTi3w2jsjfzv4aU42ND7HXo89Cv5a5y/fwuS+wNU7bZCME4tuCWFxkuR/l+J3IkEymSS++4srtx/SevEa1++186x/lPvPh2nvH6NzaJIXns90e3z0vPtC97CPriEfHQMTjEwGSCSS+xIoUs0OxOK7xGJxQlsRugY/0tbjpe3lB9nTVyN09HnpfOOV88e974URPGPT8gQHPY6MHIvFiO3syKLbYRaD6yyvrhNcCxGNbPFze4vQ+hqbG4KIkc0NUQsfHTm5/0Kp60ajUcLhCJFIhODqd6bmlpj2LzE7v8JKcJXllRXm/H78gQCB+XkWF5dYW/sh/3t4w5az52huaaWxsQm3+wwulxuXu5G6+gZsjnps9joczgbq6104nWJvc2C11opop7bWJucOh1OcN+ASPRT5+SoMBiOSsQKdwYBSU0R+gYpU/Yg8pRwLCtSHMjOzycjIJC0tnfT0DCEThd5gwlJVw8nqWiqOV1NaWkZpSRl6vVGQ9qPxcF98oFhCqdRQWKhCpdKg0xmQJDMKrUaL0VhOmbESyWBGKjGh0+opEvV/aYt06PalcqVSjVqtJS+3gOzsHHJy8lEUl1uRLE4sp5qoqmkWmjCfcIqaHaPFganKIedSpZ3iMitaUw1a82k55opnyBJjZ2UdO/QHWyRPY1ct69oAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Screenshot2019 02 01at21 d6c00a7a fa05 474c 89d6 56a21e509766 49 24\"\n        title=\"\"\n        src=\"/static/45718b260d0250147cd97ebff76e9426/6255c/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png\"\n        srcset=\"/static/45718b260d0250147cd97ebff76e9426/375dc/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 148w,\n/static/45718b260d0250147cd97ebff76e9426/6b157/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 295w,\n/static/45718b260d0250147cd97ebff76e9426/6255c/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 590w,\n/static/45718b260d0250147cd97ebff76e9426/dcf9c/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 885w,\n/static/45718b260d0250147cd97ebff76e9426/43c8a/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 1180w,\n/static/45718b260d0250147cd97ebff76e9426/1b01e/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 1440w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>Using the bs4’s function find_all, we can find all links which contain the wanted text.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    <span class=\"token comment\"># find all links with text \"Last Statement\"</span>\n    links <span class=\"token operator\">=</span> main_pg_html<span class=\"token punctuation\">.</span>find_all<span class=\"token punctuation\">(</span><span class=\"token string\">'a'</span><span class=\"token punctuation\">,</span> href<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> text<span class=\"token operator\">=</span><span class=\"token string\">\"Last Statement\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># len(links)</span>\n    <span class=\"token comment\"># links</span></code></pre></div>\n<p>Now it’s easy to get all the href’s inside the link tags. Two of the links were of different extensions compared to the others so I manually changed them. Then I defined the urls I’m going to use as the base url concatenated with the extracted links.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    <span class=\"token comment\"># get the urls</span>\n    urls <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>link<span class=\"token punctuation\">[</span><span class=\"token string\">'href'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> link <span class=\"token keyword\">in</span> links<span class=\"token punctuation\">]</span>\n    <span class=\"token comment\"># urls</span>\n    urls<span class=\"token punctuation\">[</span><span class=\"token number\">13</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'dr_info/cardenasrubenlast.html'</span>\n    urls<span class=\"token punctuation\">[</span><span class=\"token number\">14</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'dr_info/pruettrobertlast.html'</span>\n    <span class=\"token comment\"># urls</span>\n    whole_urls <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'https://www.tdcj.texas.gov/death_row/'</span> <span class=\"token operator\">+</span> url <span class=\"token keyword\">for</span> url <span class=\"token keyword\">in</span> urls<span class=\"token punctuation\">]</span>\n    <span class=\"token comment\"># whole_urls</span></code></pre></div>\n<p>Once again, the structure of the pages with the statements wasn’t unified so I had to find a pattern and apply it like this (most of the times, it ended up being the 5th paragraph).</p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/46f83bfaac08fe3a1f786972b89a900c/9d22d/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 29.464906184850587%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAABdElEQVQY01WMTU8aQQCG9w9VkN2dXXfZYUGKWhOLhpha+yFgUEA0Len/IJH2WOIHpof21AqmSc8mTQxtL3pRMMY/0FNTo4/DEr8mefI+70zm1bh/ri7g8j+X//7S6RxweHTI6ekJ3e7xgN6x6t2AnrrvqTw/O1EfL24ntEbrF3029v6wudf3Dl9+HLC/v0vj8zdqm7vUmy3q2y3WFfVmm/c7bT58+k5tqx30xteffGz9Dna0XOktueIbZuZyvC6sBj6fW6ZYLpMtrJBdWuPV4krAQqGissTLfJkX+RKL5Srz+QrZYpVC5R39Lc2POqQScRJSZVziuw6WGcEWJrapE7UFRmQowDaHMYYfIYwwph5SPYxwRrGcGJ5r4To2Wth08f0JptOzPJnM4HpjRISHbkl0Ie/ceuiGFVPp4XsJkn4SYQmEsNBCI5NERzPEx+eQ48+JPn6G8GcwvKcYMj2g714aUw64edO9KeJ+irFkCiklrutyDR+MGomm/AR3AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Screenshot2019 02 01at22 39dccc7f f8f4 4a61 a959 9d85a38a3d02 19 58\"\n        title=\"\"\n        src=\"/static/46f83bfaac08fe3a1f786972b89a900c/6255c/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png\"\n        srcset=\"/static/46f83bfaac08fe3a1f786972b89a900c/375dc/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 148w,\n/static/46f83bfaac08fe3a1f786972b89a900c/6b157/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 295w,\n/static/46f83bfaac08fe3a1f786972b89a900c/6255c/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 590w,\n/static/46f83bfaac08fe3a1f786972b89a900c/dcf9c/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 885w,\n/static/46f83bfaac08fe3a1f786972b89a900c/43c8a/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 1180w,\n/static/46f83bfaac08fe3a1f786972b89a900c/9d22d/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 1439w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>I then defined a function which goes through an array of urls, for each url processes it, gets the statement and appends it to an array.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    <span class=\"token keyword\">def</span> <span class=\"token function\">get_last_statements</span><span class=\"token punctuation\">(</span>urls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        statements <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> url <span class=\"token keyword\">in</span> urls<span class=\"token punctuation\">:</span>\n            site <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>text\n            html <span class=\"token operator\">=</span> BeautifulSoup<span class=\"token punctuation\">(</span>site<span class=\"token punctuation\">)</span>\n            ps <span class=\"token operator\">=</span> html<span class=\"token punctuation\">.</span>find_all<span class=\"token punctuation\">(</span><span class=\"token string\">'p'</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ps<span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> <span class=\"token number\">6</span><span class=\"token punctuation\">:</span>\n                statement <span class=\"token operator\">=</span> ps<span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>getText<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            statements<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>statement<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> statements</code></pre></div>\n<p>Assign the statements array with our array of links.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    last_statements <span class=\"token operator\">=</span> get_last_statements<span class=\"token punctuation\">(</span>whole_urls<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># last_statements</span></code></pre></div>\n<p>Join all the statements into one string separated by blanks:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    combined <span class=\"token operator\">=</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>statement <span class=\"token keyword\">for</span> statement <span class=\"token keyword\">in</span> last_statements<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># combined</span></code></pre></div>\n<p>Make a word cloud using the Wordcloud function (from the module of the same name) and save to a png file.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    wordcloud <span class=\"token operator\">=</span> WordCloud<span class=\"token punctuation\">(</span>max_font_size<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> max_words<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">,</span> background_color<span class=\"token operator\">=</span><span class=\"token string\">\"white\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>combined<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Display the generated image:</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>wordcloud<span class=\"token punctuation\">,</span> interpolation<span class=\"token operator\">=</span><span class=\"token string\">'bilinear'</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">\"off\"</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># save to png file</span>\n    wordcloud<span class=\"token punctuation\">.</span>to_file<span class=\"token punctuation\">(</span><span class=\"token string\">'last_statements.png'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h1>The Result</h1>\n<p><img src=\"/assets/img/last_statements-fefe8fdd-9376-4547-af05-534c1fbf37b7.png\" alt=\"Last Statements Word Cloud\"></p>\n<h1>Summary</h1>\n<p>This was a very short exercise in python and web scraping. Definitely, a lot more can be done and a more rigorous approach can be taken. For now it was a good start with immediate results, and maybe some day I’ll get back to the data in the future with more ideas. The general approach was:</p>\n<ol>\n<li>Starting point: an origin site with a bunch of links</li>\n<li>Find a way to get all the urls to the separate sites (use dev tools inspector)</li>\n<li>Get all the urls and store them in an array</li>\n<li>Investigate again with element inspector how to get a particular statement from separate site</li>\n<li>Define a function that for each url, grabs a particular statement and stores it in an array</li>\n<li>Combine all the statements into a single string and input it into the wordcloud function</li>\n</ol>","frontmatter":{"title":"Scraping and Word Clouds with Python","date":"February 01, 2019","description":"Making Word Clouds in Python"}}},"pageContext":{"slug":"/scraping-and-wordclouds-with-python/","previous":{"fields":{"slug":"/what-i-learned-from-diana/"},"frontmatter":{"title":"What I Learned From Diana"}},"next":{"fields":{"slug":"/design-thinking/"},"frontmatter":{"title":"Design Thinking"}}}}